{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810ac2da",
   "metadata": {},
   "source": [
    "## Session #1 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b63df",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fba932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the version of NumPy that you installed?\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8334e13",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e896e3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the version of Pandas?\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f473707",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40be72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine Fuel Type</th>\n",
       "      <th>Engine HP</th>\n",
       "      <th>Engine Cylinders</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Driven_Wheels</th>\n",
       "      <th>Number of Doors</th>\n",
       "      <th>Market Category</th>\n",
       "      <th>Vehicle Size</th>\n",
       "      <th>Vehicle Style</th>\n",
       "      <th>highway MPG</th>\n",
       "      <th>city mpg</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Factory Tuner,Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>3916</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Make       Model  Year             Engine Fuel Type  Engine HP  \\\n",
       "0  BMW  1 Series M  2011  premium unleaded (required)      335.0   \n",
       "1  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "2  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "3  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "4  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "\n",
       "   Engine Cylinders Transmission Type     Driven_Wheels  Number of Doors  \\\n",
       "0               6.0            MANUAL  rear wheel drive              2.0   \n",
       "1               6.0            MANUAL  rear wheel drive              2.0   \n",
       "2               6.0            MANUAL  rear wheel drive              2.0   \n",
       "3               6.0            MANUAL  rear wheel drive              2.0   \n",
       "4               6.0            MANUAL  rear wheel drive              2.0   \n",
       "\n",
       "                         Market Category Vehicle Size Vehicle Style  \\\n",
       "0  Factory Tuner,Luxury,High-Performance      Compact         Coupe   \n",
       "1                     Luxury,Performance      Compact   Convertible   \n",
       "2                Luxury,High-Performance      Compact         Coupe   \n",
       "3                     Luxury,Performance      Compact         Coupe   \n",
       "4                                 Luxury      Compact   Convertible   \n",
       "\n",
       "   highway MPG  city mpg  Popularity   MSRP  \n",
       "0           26        19        3916  46135  \n",
       "1           28        19        3916  40650  \n",
       "2           28        20        3916  36350  \n",
       "3           28        18        3916  29450  \n",
       "4           28        18        3916  34500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('car-price-data-ML ZoomCamp - Session 1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc1be3",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbaf4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean    61546.763473\n",
       "Name: BMW, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the average price of BMW cars in the dataset?\n",
    "grouped_data = data.groupby('Make')['MSRP'].agg(['mean'])\n",
    "grouped_data.loc['BMW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f31aa1",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586f236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a subset of cars after year 2015 (inclusive, i.e. 2015 and after). How many of them have missing values for Engine HP?\n",
    "Year_after_2015 = (data[data.Year >= 2015]) \n",
    "missing_HP_after_2015 = Year_after_2015['Engine HP'].isnull().sum()\n",
    "missing_HP_after_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e7e4b",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a30a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average \"Engine HP\" in the dataset.\n",
    "mean_hp_before = data['Engine HP'].mean()\n",
    "print(round(mean_hp_before))\n",
    "\n",
    "# Use the fillna method and to fill the missing values in \"Engine HP\" with the mean value from the previous step.\n",
    "data['Engine HP'].fillna(mean_hp_before, inplace=True)\n",
    "\n",
    "# Now, calcualte the average of \"Engine HP\" again.\n",
    "mean_hp_after = data['Engine HP'].mean()\n",
    "print(round(mean_hp_after))\n",
    "\n",
    "# Has it changed?\n",
    "# No Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039c1e5",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedaf026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.,   8.,  15.],\n",
       "       [563.,  12.,  19.],\n",
       "       [563.,  12.,  21.],\n",
       "       [563.,  12.,  20.],\n",
       "       [322.,  12.,  15.],\n",
       "       [453.,  12.,  19.],\n",
       "       [624.,  12.,  21.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the \"Rolls-Royce\" cars from the dataset.\n",
    "rolls_royce_data = data[data['Make'] == 'Rolls-Royce']\n",
    "\n",
    "# Select only columns \"Engine HP\", \"Engine Cylinders\", \"highway MPG\".\n",
    "select_rr = rolls_royce_data[['Engine HP','Engine Cylinders','highway MPG']]\n",
    "\n",
    "# Now drop all duplicated rows using drop_duplicates method (you should get a dataframe with 7 rows).\n",
    "unduplicated_rr = select_rr.drop_duplicates()\n",
    "\n",
    "# Get the underlying NumPy array. Let's call it X.\n",
    "X = unduplicated_rr.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64208964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.754801e+06, 3.965600e+04, 6.519600e+04],\n",
       "       [3.965600e+04, 9.280000e+02, 1.500000e+03],\n",
       "       [6.519600e+04, 1.500000e+03, 2.454000e+03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute matrix-matrix multiplication between the transpose of X and X. To get the transpose, use X.T. Let's call the result XTX.\n",
    "XTX = (X.T).dot(X)\n",
    "XTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6105dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.17815728e-05,  9.06587044e-04, -1.92984188e-03],\n",
       "       [ 9.06587044e-04,  1.05723058e-01, -8.87084092e-02],\n",
       "       [-1.92984188e-03, -8.87084092e-02,  1.05900809e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invert XTX.\n",
    "inverse_XTX = np.linalg.inv(XTX)\n",
    "inverse_XTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780b246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all the elements is 0.032212320677486195\n"
     ]
    }
   ],
   "source": [
    "# What's the sum of all the elements of the result?\n",
    "total = np.sum(inverse_XTX)\n",
    "print(f'Sum of all the elements is {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14063a",
   "metadata": {},
   "source": [
    "### Questions 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50efcba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19989598183186175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array y with values [1000, 1100, 900, 1200, 1000, 850, 1300].\n",
    "y = np.array([1000, 1100, 900, 1200, 1000, 850, 1300])\n",
    "y\n",
    "\n",
    "# Multiply the inverse of XTX with the transpose of X, and then multiply the result by y. Call the result w.\n",
    "#print(inverse_XTX * (X.T))\n",
    "m = inverse_XTX.dot(X.T)\n",
    "w = m.dot(y)\n",
    "\n",
    "# What's the value of the first element of w?.\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98df45e",
   "metadata": {},
   "source": [
    "## Session #2 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d429590",
   "metadata": {},
   "source": [
    "###  Create a regression model for prediction apartment prices - \n",
    "\n",
    "#### (using New York City Airbnb Open Data)\n",
    "\n",
    "Datset - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b211b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad48a38",
   "metadata": {},
   "source": [
    "#### EDA\n",
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e158ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5edae",
   "metadata": {},
   "source": [
    "Look at the price variable. Does it have a long tail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7377169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.price.describe()\n",
    "\n",
    "# Computing the log of price column values:\n",
    "price_logs = np.log1p(data.price)\n",
    "\n",
    "# plotting the logarithmic price column values:\n",
    "sns.histplot(price_logs,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240bad1",
   "metadata": {},
   "source": [
    "Plotting the logarithmic values of price column shows that price variable has a long tail towards the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ecdca",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d8c8386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237    149               1                  9   \n",
       "1  40.75362  -73.98377    225               1                 45   \n",
       "2  40.80902  -73.94190    150               3                  0   \n",
       "3  40.68514  -73.95976     89               1                270   \n",
       "4  40.79851  -73.94399     80              10                  9   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only specific columns from dataset for future use.\n",
    "features = data[['latitude','longitude','price','minimum_nights','number_of_reviews','reviews_per_month',\n",
    "'calculated_host_listings_count','availability_365']]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905589b5",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Find a feature with missing values. How many missing values does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "038d5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                              0\n",
       "longitude                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01e7fb",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the median (50% percentile) for variable 'minimum_nights'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a179d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48895.000000\n",
       "mean         7.029962\n",
       "std         20.510550\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          3.000000\n",
       "75%          5.000000\n",
       "max       1250.000000\n",
       "Name: minimum_nights, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['minimum_nights'].describe()   # 50th percentile is the same as the median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f66d3",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b3e8810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 48895)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "n = len(data)\n",
    "\n",
    "n_val = int(n * 0.2)   # split 20% into validation set\n",
    "n_test = int(n * 0.2)  # split 20% into testing set\n",
    "n_train = n - n_val - n_test  # remaining training set\n",
    "n, n_val + n_test + n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "689794de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9779, 9779, 29337)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the size of the splitted datasets:\n",
    "n_val, n_test, n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd7cb8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  879, 44383, 15394, ..., 38158,   860, 15795])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the initial dataset, use seed 42.\n",
    "idx = np.arange(n)\n",
    "np.random.seed(42)\n",
    "\n",
    "np.random.shuffle(idx)  # shuffle the data from index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f58cb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9779, 16) (9779, 16) (29337, 16)\n"
     ]
    }
   ],
   "source": [
    "# getting the rows for each set from the shuffled indices:\n",
    "df_val = data.iloc[idx[:n_val]]\n",
    "df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "df_train = data.iloc[idx[n_val + n_test:]]\n",
    "\n",
    "print(df_val.shape, df_test.shape,df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7267a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "# # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "y_val = np.log1p(df_val.price.values)\n",
    "y_test = np.log1p(df_test.price.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d6b9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9779, 15) (9779, 15) (29337, 15)\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "# deleting the price column from Feature matrices of train, validation and test set:\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']\n",
    "\n",
    "print(df_val.shape, df_test.shape,df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b83884",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "#### Option 1 - Filling NaN with 0 - Training  a linear regression model without regularization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a8a9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_features = ['latitude','longitude','minimum_nights','number_of_reviews','reviews_per_month',\n",
    "'calculated_host_listings_count','availability_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "696ac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to extract a subset of a df as an array - \n",
    "def prepare_X(df):\n",
    "    \n",
    "    df_num = df[subset_features]  # feature columns we want in our feature matrix subset\n",
    "    df_num = df_num.fillna(0)  # fill missing values with zeros\n",
    "    X = df_num.values   # extracting only values of subset as a Numpy array\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d0cc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing only above feature columns to create a subset of training dataset:\n",
    "X_train = prepare_X(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "740d038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to predict car price's using 3 features - \n",
    "def train_linear_regression(X,y):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 5 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 6 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15f68dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.87791291, 4.81288069, 5.55153718, ..., 5.02356152, 4.88478955,\n",
       "       4.66641733])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Linear regression model (function) for the training sets to get weights w0 and w:\n",
    "w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "# computing target variable y_pred -\n",
    "# using weights w0 and w to compute the target variable y_pred:\n",
    "y_pred = w0 + X_train.dot(w)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6146398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the RMSE of actual target variable vs. predicted target variables:\n",
    "def rmse(y,y_pred):\n",
    "    # computing the squared error first:\n",
    "    se = (y - y_pred) ** 2  \n",
    "    # computing the mean of squared errors computed:\n",
    "    mse = se.mean()\n",
    "    # returning the square root of squared error:\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947381a6",
   "metadata": {},
   "source": [
    "#### Option 2 - Filling NaN with Mean value - Training a linear regression model without regularization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5decfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to extract a subset of a df as an array - \n",
    "def prepare_X2(df):\n",
    "    df_num = df[subset_features]  # feature columns we want in our feature matrix subset\n",
    "    df_num = df_num.fillna(df_train['reviews_per_month'].mean())  # fill missing values with mean of column\n",
    "    X2 = df_num.values   # extracting only values of subset as a Numpy array\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5969f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing only above feature columns to create a subset of training dataset:\n",
    "X_train_2 = prepare_X2(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d88377ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to predict car price's using 3 features - \n",
    "def train_linear_regression2(X,y):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 5 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 6 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c57d1b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.86744762, 4.80488808, 5.54883838, ..., 5.01686784, 4.87418674,\n",
       "       4.65564306])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Linear regression model (function) for the training sets to get weights w0 and w:\n",
    "w0, w = train_linear_regression2(X_train_2, y_train)\n",
    "\n",
    "# computing target variable y_pred -\n",
    "# using weights w0 and w to compute the target variable y_pred:\n",
    "y_pred = w0 + X_train_2.dot(w)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5cb6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the RMSE of actual target variable vs. predicted target variables:\n",
    "def rmse2(y,y_pred):\n",
    "    # computing the squared error first:\n",
    "    se = (y - y_pred) ** 2  \n",
    "    # computing the mean of squared errors computed:\n",
    "    mse = se.mean()\n",
    "    # returning the square root of squared error:\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919619a",
   "metadata": {},
   "source": [
    "#### Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "\n",
    "Option 1 - Filling NaN with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5456bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing subset feature array on to create a validation set:\n",
    "X_val = prepare_X(df_val)\n",
    "\n",
    "y_pred = w0 + X_val.dot(w)   # computing the predicted target variable y for validation set\n",
    "val_score = rmse(y_val, y_pred)   # computing the rmse for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a7ad4",
   "metadata": {},
   "source": [
    "Option 2 - Filling NaN with Mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7266b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing subset feature array on to create a validation set:\n",
    "X_val = prepare_X2(df_val)\n",
    "\n",
    "y_pred = w0 + X_val.dot(w)   # computing the predicted target variable y for validation set\n",
    "val_score2 = rmse2(y_val, y_pred)   # computing the rmse for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ff44a",
   "metadata": {},
   "source": [
    "Which option gives better RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1262ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 RMSE: 0.64\n",
      "Option 2 RMSE: 0.64\n"
     ]
    }
   ],
   "source": [
    "# ound the RMSE scores to 2 decimal digits using round(score, 2)\n",
    "print('Option 1 RMSE:',round(val_score,2))\n",
    "print('Option 2 RMSE:',round(val_score2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416172b",
   "metadata": {},
   "source": [
    "Both Options give almost same RMSE value on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c025c",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Now let's train a regularized linear regression. \n",
    "\n",
    "For this question, fill the NAs with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faef5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Regularized function to predict price using features - \n",
    "def train_linear_regression_reg(X,y,r):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - # add the alpha term r to diagonals of matrix use np.eye() function:\n",
    "    XTX = XTX + r * np.eye(XTX.shape[0])   \n",
    "    \n",
    "    # Step 5 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 6 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 7 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666c2c9",
   "metadata": {},
   "source": [
    "Try different values of r from this list: [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10].\n",
    "    \n",
    "Use RMSE to evaluate the model on the validation dataset.\n",
    "\n",
    "Round the RMSE scores to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "069e4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -385.59 RMSE : 29.68\n",
      "1e-06 -385.59 RMSE : 29.63\n",
      "0.0001 -385.59 RMSE : 24.84\n",
      "0.001 -385.59 RMSE : 14.15\n",
      "0.01 -385.59 RMSE : 195.04\n",
      "0.1 -385.59 RMSE : 353.12\n",
      "1 -385.59 RMSE : 382.09\n",
      "5 -385.59 RMSE : 384.88\n",
      "10 -385.59 RMSE : 385.23\n"
     ]
    }
   ],
   "source": [
    "# Using the newly created Regularized function:\n",
    "# Finding the best regularization parameter, r for our Linear Regression model - \n",
    "# taking a series of r values to test our model and find the RMSE score for each:\n",
    "for m in [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n",
    "    \n",
    "    X_train = prepare_X(df_train)   # function replaces NaN with zeros\n",
    "    wo, w = train_linear_regression_reg(X_train, y_train,r=m)   # training set\n",
    "    \n",
    "    X_val = prepare_X(df_val)    # validation set\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "\n",
    "    score = rmse(y_val,y_pred)   # comparing actual vs prediction target variable in validation set\n",
    "    print(m, round(w0,2), 'RMSE :',round(score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bfc15",
   "metadata": {},
   "source": [
    "#### Which r gives the best RMSE?\n",
    "r = 0.0001 gives a RMSE of 8.42 which is low but not extremely low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f6c1f",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28648e14",
   "metadata": {},
   "source": [
    "We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "\n",
    "Try different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].\n",
    "\n",
    "Fill the missing values with 0 and train a model without regularization.\n",
    "\n",
    "For each seed, evaluate the model on the validation dataset and collect the RMSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6306547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [43813 32734 25276 ... 42613 43567  2732] -443.49 RMSE: 23.14\n",
      "1 [18907 46663 19757 ...  5192 12172 33003] -443.49 RMSE: 7.64\n",
      "2 [22043 39679 45220 ...  6637 35343 23720] -443.49 RMSE: 19.56\n",
      "3 [ 6920 38903 30764 ... 11513  1688  5994] -443.49 RMSE: 17.6\n",
      "4 [25022 38145  2095 ... 27063  8366 17530] -443.49 RMSE: 19.35\n",
      "5 [20531 20353 26436 ... 20463 18638 35683] -443.49 RMSE: 26.13\n",
      "6 [27383  7800 18787 ... 42964 41187 31626] -443.49 RMSE: 22.89\n",
      "7 [13636 25054 15227 ...   919 38467 10742] -443.49 RMSE: 20.78\n",
      "8 [42099 22672  8754 ... 18417 25940  4547] -443.49 RMSE: 21.53\n",
      "9 [25415  1329 31738 ... 22584   501 20828] -443.49 RMSE: 28.24\n"
     ]
    }
   ],
   "source": [
    "RMSE_scores = []\n",
    "\n",
    "for a in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    # For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n",
    "    n = len(data)\n",
    "\n",
    "    # Shuffle the initial dataset, use different seed values from list:\n",
    "    np.random.seed(a)\n",
    "    \n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)# shuffle the data from index\n",
    "    \n",
    "    n_val = int(n * 0.2)   # split 20% into validation set\n",
    "    n_test = int(n * 0.2)  # split 20% into testing set\n",
    "    n_train = n - n_val - n_test  # remaining training set\n",
    "\n",
    "\n",
    "    # getting the rows for each set from the shuffled indices:\n",
    "    df_val = data.iloc[idx[:n_val]]\n",
    "    df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "    df_train = data.iloc[idx[n_val + n_test:]]\n",
    "   \n",
    "    # Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "    # # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "    y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "    y_val = np.log1p(df_val.price.values)\n",
    "    y_test = np.log1p(df_test.price.values)\n",
    "    \n",
    "\n",
    "    # Make sure that the target value ('price') is not in your dataframe.\n",
    "    # deleting the price column from Feature matrices of train, validation and test set:\n",
    "    del df_train['price']\n",
    "    del df_val['price']\n",
    "    del df_test['price']\n",
    "\n",
    "    X_train = prepare_X(df_train)   # function replaces NaN with zeros\n",
    "       \n",
    "    # Training a model without regularization:\n",
    "    wo, w = train_linear_regression(X_train, y_train)   # training set\n",
    "\n",
    "    X_val = prepare_X(df_val) # validation set\n",
    "    \n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "\n",
    "    score = rmse(y_val,y_pred)   # comparing actual vs prediction target variable in validation set\n",
    "    \n",
    "    print(a, idx, round(w0,2),'RMSE:',round(score,2))   \n",
    "    RMSE_scores.append(score)\n",
    "\n",
    "RMSE_std = np.std(RMSE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "baee8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302255023811292"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(RMSE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18ed8551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the standard deviation of all the scores? To compute the standard deviation, use np.std:\n",
    "RMSE_std\n",
    "\n",
    "# Round the result to 3 decimal digits:\n",
    "(round(RMSE_std, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c1ef0",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "483844b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset like previously, use seed 9.\n",
    "n = len(data)\n",
    "\n",
    "# Shuffle the initial dataset, use different seed values from list:\n",
    "np.random.seed(9)\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)# shuffle the data from index\n",
    "    \n",
    "n_val = int(n * 0.2)   # split 20% into validation set\n",
    "n_test = int(n * 0.2)  # split 20% into testing set\n",
    "n_train = n - n_val - n_test  # remaining training set\n",
    "\n",
    "# getting the rows for each set from the shuffled indices:\n",
    "df_val = data.iloc[idx[:n_val]]\n",
    "df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "df_train = data.iloc[idx[n_val + n_test:]]\n",
    "   \n",
    "# Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "# # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "y_val = np.log1p(df_val.price.values)\n",
    "y_test = np.log1p(df_test.price.values)\n",
    "    \n",
    "\n",
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "# deleting the price column from Feature matrices of train, validation and test set:\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e19624",
   "metadata": {},
   "source": [
    "Combine train and validation datasets.\n",
    "\n",
    "Fill the missing values with 0 and train a model with r=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "181d8493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6404588269895755"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train = pd.concat([df_train,df_val])\n",
    "# resetting index of combined training set:\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "# Combining features matrix for training and validation set using full training set as input to the prepare_X  function:\n",
    "X_full_train = prepare_X(df_full_train)\n",
    "X_full_train \n",
    "\n",
    "# Combining y target variable array of training and validation set:\n",
    "y_full_train = np.concatenate([y_train, y_val])\n",
    "y_full_train\n",
    "\n",
    "\n",
    "# Running the Regularized linear regression model and calculating the RMSE score on testing dataset:\n",
    "w0, w = train_linear_regression_reg(X_full_train,y_full_train, r=0.001)\n",
    "\n",
    "X_test = prepare_X(df_test)\n",
    "y_pred = w0 + X_test.dot(w)\n",
    "score = rmse(y_test, y_pred)\n",
    "\n",
    "# What's the RMSE on the test dataset?\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39663ecd",
   "metadata": {},
   "source": [
    "## Session #3 Homework\n",
    "\n",
    "Datset - continue the New York City Airbnb Open Data\n",
    "\n",
    "https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e9c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9122474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98d27199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28c61a",
   "metadata": {},
   "source": [
    "#### Features - \n",
    "\n",
    "Features from the previous homework with additional two 'neighbourhood_group' and 'room_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82444523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>room_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group        room_type  latitude  longitude  price  \\\n",
       "0            Brooklyn     Private room  40.64749  -73.97237    149   \n",
       "1           Manhattan  Entire home/apt  40.75362  -73.98377    225   \n",
       "2           Manhattan     Private room  40.80902  -73.94190    150   \n",
       "3            Brooklyn  Entire home/apt  40.68514  -73.95976     89   \n",
       "4           Manhattan  Entire home/apt  40.79851  -73.94399     80   \n",
       "\n",
       "   minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "0               1                  9               0.21   \n",
       "1               1                 45               0.38   \n",
       "2               3                  0                NaN   \n",
       "3               1                270               4.64   \n",
       "4              10                  9               0.10   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               6               365  \n",
       "1                               2               355  \n",
       "2                               1               365  \n",
       "3                               1               194  \n",
       "4                               1                 0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data[['neighbourhood_group','room_type','latitude','longitude','price','minimum_nights','number_of_reviews',\n",
    "            'reviews_per_month','calculated_host_listings_count','availability_365']]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff14c9d",
   "metadata": {},
   "source": [
    "Select only them and fill in the missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1f4c29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group                   0\n",
       "room_type                             0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before filling NaN:\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e98103ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group               0\n",
       "room_type                         0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after filling NaN with zeros:\n",
    "features = features.fillna(0)\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0f672",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column 'neighbourhood_group'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e0e066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Manhattan\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1 - using mode() function\n",
    "features.neighbourhood_group.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1953c379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manhattan        21661\n",
       "Brooklyn         20104\n",
       "Queens            5666\n",
       "Bronx             1091\n",
       "Staten Island      373\n",
       "Name: neighbourhood_group, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2 - using value_counts() and selecting the first row variable:\n",
    "features['neighbourhood_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b69ef",
   "metadata": {},
   "source": [
    "#### Split the data - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b9de2099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29337, 10), (9779, 10), (9779, 10))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "# Step 1 - splitting dataset into full train and test sets first:\n",
    "df_full_train, df_test = train_test_split(features, test_size=0.20,random_state=42) \n",
    "\n",
    "# Step 2 - splitting full train set again into training set and validation set:\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,random_state = 42)\n",
    "\n",
    "# getting the size of train, vaidation and test set:\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7dfae465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29337, 9), (9779, 9), (9779, 9))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting our target variable column (price) subsets as respective Numpy arrays:\n",
    "y_train = df_train.price.values\n",
    "y_val = df_val.price.values\n",
    "y_test = df_test.price.values\n",
    "\n",
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']\n",
    "\n",
    "# getting the size of train, vaidation and test set after deleting price column:\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26f5e",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54366dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29337 entries, 13575 to 20523\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   neighbourhood_group             29337 non-null  object \n",
      " 1   room_type                       29337 non-null  object \n",
      " 2   latitude                        29337 non-null  float64\n",
      " 3   longitude                       29337 non-null  float64\n",
      " 4   minimum_nights                  29337 non-null  int64  \n",
      " 5   number_of_reviews               29337 non-null  int64  \n",
      " 6   reviews_per_month               29337 non-null  float64\n",
      " 7   calculated_host_listings_count  29337 non-null  int64  \n",
      " 8   availability_365                29337 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# getting the datatypes of columns in train dataset:\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5996948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing only numerical feature columns of train dataset:\n",
    "numerical = ['latitude','longitude','minimum_nights','number_of_reviews', 'reviews_per_month',\n",
    "             'calculated_host_listings_count', 'availability_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8666cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080704</td>\n",
       "      <td>0.025497</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.013809</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>-0.008341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.080704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063498</td>\n",
       "      <td>0.057570</td>\n",
       "      <td>0.134401</td>\n",
       "      <td>-0.115289</td>\n",
       "      <td>0.082994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>0.025497</td>\n",
       "      <td>-0.063498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077860</td>\n",
       "      <td>-0.121687</td>\n",
       "      <td>0.121748</td>\n",
       "      <td>0.140596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>-0.011836</td>\n",
       "      <td>0.057570</td>\n",
       "      <td>-0.077860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584935</td>\n",
       "      <td>-0.072603</td>\n",
       "      <td>0.175428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>-0.013809</td>\n",
       "      <td>0.134401</td>\n",
       "      <td>-0.121687</td>\n",
       "      <td>0.584935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047368</td>\n",
       "      <td>0.165565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>0.020299</td>\n",
       "      <td>-0.115289</td>\n",
       "      <td>0.121748</td>\n",
       "      <td>-0.072603</td>\n",
       "      <td>-0.047368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>-0.008341</td>\n",
       "      <td>0.082994</td>\n",
       "      <td>0.140596</td>\n",
       "      <td>0.175428</td>\n",
       "      <td>0.165565</td>\n",
       "      <td>0.223328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                latitude  longitude  minimum_nights  \\\n",
       "latitude                        1.000000   0.080704        0.025497   \n",
       "longitude                       0.080704   1.000000       -0.063498   \n",
       "minimum_nights                  0.025497  -0.063498        1.000000   \n",
       "number_of_reviews              -0.011836   0.057570       -0.077860   \n",
       "reviews_per_month              -0.013809   0.134401       -0.121687   \n",
       "calculated_host_listings_count  0.020299  -0.115289        0.121748   \n",
       "availability_365               -0.008341   0.082994        0.140596   \n",
       "\n",
       "                                number_of_reviews  reviews_per_month  \\\n",
       "latitude                                -0.011836          -0.013809   \n",
       "longitude                                0.057570           0.134401   \n",
       "minimum_nights                          -0.077860          -0.121687   \n",
       "number_of_reviews                        1.000000           0.584935   \n",
       "reviews_per_month                        0.584935           1.000000   \n",
       "calculated_host_listings_count          -0.072603          -0.047368   \n",
       "availability_365                         0.175428           0.165565   \n",
       "\n",
       "                                calculated_host_listings_count  \\\n",
       "latitude                                              0.020299   \n",
       "longitude                                            -0.115289   \n",
       "minimum_nights                                        0.121748   \n",
       "number_of_reviews                                    -0.072603   \n",
       "reviews_per_month                                    -0.047368   \n",
       "calculated_host_listings_count                        1.000000   \n",
       "availability_365                                      0.223328   \n",
       "\n",
       "                                availability_365  \n",
       "latitude                               -0.008341  \n",
       "longitude                               0.082994  \n",
       "minimum_nights                          0.140596  \n",
       "number_of_reviews                       0.175428  \n",
       "reviews_per_month                       0.165565  \n",
       "calculated_host_listings_count          0.223328  \n",
       "availability_365                        1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the correlation matrix for the numerical features of your train dataset:\n",
    "df_full_train[numerical].corr()   # using corr() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7af61e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "availability_365                  0.080562\n",
       "calculated_host_listings_count    0.055336\n",
       "minimum_nights                    0.042740\n",
       "latitude                          0.035015\n",
       "number_of_reviews                -0.048926\n",
       "reviews_per_month                -0.051978\n",
       "longitude                        -0.149080\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the correlation for the numerical features of your train dataset with target column, price:\n",
    "df_full_train[numerical].corrwith(df_full_train.price).sort_values(ascending = False)   # using corr() function\n",
    "\n",
    "# sorting in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57401e36",
   "metadata": {},
   "source": [
    "What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "availability_365 \n",
    "\n",
    "calculated_host_listings_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5836a2d",
   "metadata": {},
   "source": [
    "### Make price binary\n",
    "\n",
    "We need to turn the price variable from numeric into binary.\n",
    "\n",
    "Let's create a variable above_average which is 1 if the price is above (or equal to) 152."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02a919",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    " Step 1 turning each row into a dictionary using to_dict() function with orient argument records:\n",
    "dicts = df_full_train[['availability_365','calculated_host_listings_count']].iloc[:10].to_dict(orient='records') # first 10 rows\n",
    "\n",
    " Step 2 - creating an instance of the class DictVectorizer()\n",
    "dv = DictVectorizer(sparse=False)   # turns off result as a sparse matrix instead produces a Numpy array\n",
    "\n",
    " Step 3 - training DictVectorizer with our data using fit() method:\n",
    "dv.fit(dicts)\n",
    "\n",
    " Step 4 - transforming the vectorizer to our data subset:\n",
    "transformed_vector = dv.transform(dicts)   # results in a sparse matrix as most values are zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9ceb1",
   "metadata": {},
   "source": [
    "if transformed_vector[0][2] >= 152:\n",
    "    above_average = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2db4f",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1c311a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type              0.31\n",
       "neighbourhood_group    0.11\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing mutual information in sklearn:\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "categ_features = ['neighbourhood_group','room_type']\n",
    "\n",
    "# Computing the Mutual information score for all feature columns - using apply() function:\n",
    "# Step 1 - embedding the mutual_info_score function in another function - \n",
    "def mutual_info_price_score(series):\n",
    "    return mutual_info_score(series, df_full_train.price)\n",
    "\n",
    "# Step 2 - calling above function in apply() function so as to apply it to each column from df - \n",
    "score = df_full_train[categ_features].apply(mutual_info_price_score)  # here applied only to 2 categorical columns\n",
    "\n",
    "# Round it to 2 decimal digits using round(score, 2):\n",
    "score.sort_values(ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fcca0",
   "metadata": {},
   "source": [
    "Which of these two variables has bigger score?\n",
    "\n",
    "room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1af97",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Now let's train a logistic regression\n",
    "\n",
    "Remember that we have two categorical variables in the data. Include them using one-hot encoding.\n",
    "\n",
    "Fit the model on the training dataset.\n",
    "\n",
    "To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
    "\n",
    "Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7d1a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Step 1 - Including two categorical variables using one-hot encoding - \n",
    "# creating an instance of the class DictVectorizer()\n",
    "dv = DictVectorizer(sparse=False)   # turns off result as a sparse matrix instead produces a Numpy array\n",
    "\n",
    "train_dicts = df_train[categ_features + numerical].to_dict(orient='records')\n",
    "\n",
    "# Combined fit and transform dictionary - for training dataset:\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Step 2 - repeating above process for validation dataset:\n",
    "# Combined fit and transform dictionary - for validation dataset:\n",
    "val_dicts = df_val[categ_features + numerical].to_dict(orient='records')\n",
    "\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b02c64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install_files\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3 - Fitting the model on the training dataset -\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# intitiating Log. regression model and trainingit on our full train set:\n",
    "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42) \n",
    "\n",
    "# solver='lbfgs'  - default solver in newer version of sklearn, need to specify it explicitly for older versions\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7403e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 =  0.00014222330952529745\n",
      "\n",
      "wi =  [-0.002 -0.007  0.006 -0.01   0.005  0.     0.001 -0.001 -0.    -0.\n",
      "  0.018  0.001 -0.001  0.     0.   ]\n"
     ]
    }
   ],
   "source": [
    "# model intercept: Bias Term (w0)\n",
    "print(\"w0 = \", model.intercept_[0])\n",
    "\n",
    "print()\n",
    "\n",
    "# Coeffficients: Weights (wi)\n",
    "print(\"wi = \",model.coef_[0].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e490b6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00029532, 0.00025794, 0.00034261, ..., 0.0002716 , 0.00026713,\n",
       "       0.00027352])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - Calculating the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "# for validation set:\n",
    "y_pred = model.predict_proba(X_val)[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42ef8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the actual target variable column, price as binary -\n",
    "# Creating a variable above_average which is 1 if the price is above (or equal to) 152.\n",
    "binary_price = []\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i] >= 152:\n",
    "        above_average = 1\n",
    "        binary_price.append(above_average)\n",
    "    else:\n",
    "        below_average = 0\n",
    "        binary_price.append(below_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52cf1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making price decision using probability threshold of 0.5\n",
    "price_decision = (y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d660eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>actual</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>0.000308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0.000272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9779 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      probability  prediction  actual  correct\n",
       "0        0.000295           0       0     True\n",
       "1        0.000258           0       0     True\n",
       "2        0.000343           0       1    False\n",
       "3        0.000271           0       0     True\n",
       "4        0.000236           0       1    False\n",
       "...           ...         ...     ...      ...\n",
       "9774     0.000269           0       1    False\n",
       "9775     0.000308           0       0     True\n",
       "9776     0.000272           0       0     True\n",
       "9777     0.000267           0       0     True\n",
       "9778     0.000274           0       0     True\n",
       "\n",
       "[9779 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy Rate: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observe the above result in a dataset\n",
    "df_pred = pd.DataFrame()\n",
    "df_pred['probability'] = y_pred\n",
    "df_pred['prediction'] = price_decision.astype(int)\n",
    "df_pred['actual'] = binary_price   # using the encoded binary price variable as actual price column, y_val\n",
    "\n",
    "df_pred['correct'] = df_pred.prediction == df_pred.actual\n",
    "\n",
    "# Accuracy Rate: mean of correct predictions\n",
    "display(df_pred)\n",
    "display(\"Accuracy Rate: \", df_pred['correct'].mean().round(2))   #(y_val == price_decision).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf262231",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "We have 9 features: 7 numerical features and 2 categorical.\n",
    "\n",
    "Let's find the least useful one using the feature elimination technique.\n",
    "\n",
    "Train a model with all these features (using the same parameters as in Q4).\n",
    "\n",
    "Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "\n",
    "For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "neighbourhood_group\n",
    "\n",
    "room_type\n",
    "\n",
    "number_of_reviews\n",
    "\n",
    "reviews_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4eb1da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['availability_365',\n",
       " 'calculated_host_listings_count',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'minimum_nights',\n",
       " 'neighbourhood_group=Bronx',\n",
       " 'neighbourhood_group=Brooklyn',\n",
       " 'neighbourhood_group=Manhattan',\n",
       " 'neighbourhood_group=Queens',\n",
       " 'neighbourhood_group=Staten Island',\n",
       " 'number_of_reviews',\n",
       " 'reviews_per_month',\n",
       " 'room_type=Entire home/apt',\n",
       " 'room_type=Private room',\n",
       " 'room_type=Shared room']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the list of all features in the vectorizer:\n",
    "dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec052b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'availability_365': -0.002,\n",
       " 'calculated_host_listings_count': -0.007,\n",
       " 'latitude': 0.006,\n",
       " 'longitude': -0.01,\n",
       " 'minimum_nights': 0.005,\n",
       " 'neighbourhood_group=Bronx': 0.0,\n",
       " 'neighbourhood_group=Brooklyn': 0.001,\n",
       " 'neighbourhood_group=Manhattan': -0.001,\n",
       " 'neighbourhood_group=Queens': -0.0,\n",
       " 'neighbourhood_group=Staten Island': -0.0,\n",
       " 'number_of_reviews': 0.018,\n",
       " 'reviews_per_month': 0.001,\n",
       " 'room_type=Entire home/apt': -0.001,\n",
       " 'room_type=Private room': 0.0,\n",
       " 'room_type=Shared room': 0.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the feature_names with respective coefficients - using zip function:\n",
    "feature_weights = dict(zip(dv.get_feature_names(), model.coef_[0].round(3)))\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5e82878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install_files\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - Training a model with all these features (using the same parameters as in Q4):\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22704814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6934246855506698"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 - Calculating the original accuracy for model (with all features):\n",
    "y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "(binary_price == price_decision).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6fce158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Now excluding each feature from this set and train a model without it and recording the accuracy for each model.\n",
    "# creating an instance of the class DictVectorizer()\n",
    "dv = DictVectorizer(sparse=False)   # turns off result as a sparse matrix instead produces a Numpy array\n",
    "\n",
    "train_dicts = df_train[categ_features + numerical].to_dict(orient = 'records')\n",
    "\n",
    "# Combined fit and transform dictionary - for training dataset:\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Step 2 - repeating above process for validation dataset:\n",
    "# Combined fit and transform dictionary - for validation dataset:\n",
    "val_dicts = df_val[categ_features + numerical].to_dict(orient = 'records')\n",
    "\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "80357d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d532bb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'room_type': 'Private room',\n",
       " 'latitude': 40.70239,\n",
       " 'longitude': -73.92931,\n",
       " 'minimum_nights': 1,\n",
       " 'number_of_reviews': 35,\n",
       " 'reviews_per_month': 1.8,\n",
       " 'calculated_host_listings_count': 1,\n",
       " 'availability_365': 52}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dicts_2 = removekey(val_dicts[0], 'neighbourhood_group')\n",
    "val_dicts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9dcdd1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 52.     ,   1.     ,  40.70239, -73.92931,   1.     ,   0.     ,\n",
       "          0.     ,   0.     ,   0.     ,   0.     ,  35.     ,   1.8    ,\n",
       "          0.     ,   1.     ,   0.     ]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_new = dv.transform([val_dicts_2])\n",
    "X_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ce635181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002964699340285137"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_val_new)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f435c04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000298983068865423"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dicts_3 = removekey(val_dicts[0], 'room_type')\n",
    "X_val_new2 = dv.transform([val_dicts_3])\n",
    "model.predict_proba(X_val_new2)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "75441453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_install_files\\envs\\ml-zoomcamp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6934246855506698"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3 - Fitting the model on the training dataset -\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# intitiating Log. regression model and trainingit on our full train set:\n",
    "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42) \n",
    "\n",
    "# solver='lbfgs'  - default solver in newer version of sklearn, need to specify it explicitly for older versions\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Step 4 - Calculating the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "# for validation set:\n",
    "y_pred = model.predict_proba(X_val_new)[:,1]\n",
    "\n",
    "(binary_price == price_decision).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "176cc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Calculating the difference between the original accuracy and the accuracy without the feature:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c092ebd",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "001f61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to use the original column 'price'. Apply the logarithmic transformation to this column.\n",
    "y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "y_val = np.log1p(df_val.price.values)\n",
    "y_test = np.log1p(df_test.price.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "01e74df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:   0 RMSE:  0.497\n",
      "alpha:   0.01 RMSE:  0.497\n",
      "alpha:   0.1 RMSE:  0.497\n",
      "alpha:   1 RMSE:  0.497\n",
      "alpha:   10 RMSE:  0.498\n"
     ]
    }
   ],
   "source": [
    "# Fit the Ridge regression model on the training data.\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# defining the model:\n",
    "for a in [0, 0.01, 0.1, 1, 10]:\n",
    "    model = Ridge(alpha=a)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate model calculated as RMSE:\n",
    "    pred = model.predict(X_val) \n",
    "    rms = mean_squared_error(y_val, pred,squared=False)\n",
    "    \n",
    "    # printing alpha and corresponding RMSE:\n",
    "    print('alpha:  ', a, 'RMSE: ',rms.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061dcbdb",
   "metadata": {},
   "source": [
    "Best alpha - 0.01 as it gives least error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5557e0",
   "metadata": {},
   "source": [
    "## Session #4 Homework\n",
    "\n",
    "Use this notebook as a starter - https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/04-evaluation/homework-4-starter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5dfb4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5670c",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "01cdc651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'seniority', 'home', 'time', 'age', 'marital', 'records',\n",
       "       'job', 'expenses', 'income', 'assets', 'debt', 'amount', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6868cd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  seniority  home  time  age  marital  records  job  expenses  \\\n",
       "0       1          9     1    60   30        2        1    3        73   \n",
       "1       1         17     1    60   58        3        1    1        48   \n",
       "2       2         10     2    36   46        2        2    3        90   \n",
       "3       1          0     1    60   24        1        1    1        63   \n",
       "4       1          0     1    36   26        1        1    1        46   \n",
       "\n",
       "   income  assets  debt  amount  price  \n",
       "0     129       0     0     800    846  \n",
       "1     131       0     0    1000   1658  \n",
       "2     200    3000     0    2000   2985  \n",
       "3     182    2500     0     900   1325  \n",
       "4     107       0     0     310    910  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45660c",
   "metadata": {},
   "source": [
    "Some of the features are encoded as numbers. Use the following code to de-code them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "99703d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d0899",
   "metadata": {},
   "source": [
    "Prepare the numerical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f42dc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5dc7a",
   "metadata": {},
   "source": [
    "Remove clients with unknown default status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "592585b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b1927",
   "metadata": {},
   "source": [
    "Create the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "951dd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "157fa005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>widow</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>owner</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>freelance</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seniority   home  time  age  marital records        job  expenses  income  \\\n",
       "0          9   rent    60   30  married      no  freelance        73     129   \n",
       "1         17   rent    60   58    widow      no      fixed        48     131   \n",
       "2         10  owner    36   46  married     yes  freelance        90     200   \n",
       "3          0   rent    60   24   single      no      fixed        63     182   \n",
       "4          0   rent    36   26   single      no      fixed        46     107   \n",
       "\n",
       "   assets  debt  amount  price  default  \n",
       "0       0     0     800    846        0  \n",
       "1       0     0    1000   1658        0  \n",
       "2    3000     0    2000   2985        1  \n",
       "3    2500     0     900   1325        0  \n",
       "4       0     0     310    910        0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1e3d327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4454 entries, 0 to 4453\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   seniority  4454 non-null   int64 \n",
      " 1   home       4454 non-null   object\n",
      " 2   time       4454 non-null   int64 \n",
      " 3   age        4454 non-null   int64 \n",
      " 4   marital    4454 non-null   object\n",
      " 5   records    4454 non-null   object\n",
      " 6   job        4454 non-null   object\n",
      " 7   expenses   4454 non-null   int64 \n",
      " 8   income     4454 non-null   int64 \n",
      " 9   assets     4454 non-null   int64 \n",
      " 10  debt       4454 non-null   int64 \n",
      " 11  amount     4454 non-null   int64 \n",
      " 12  price      4454 non-null   int64 \n",
      " 13  default    4454 non-null   int32 \n",
      "dtypes: int32(1), int64(9), object(4)\n",
      "memory usage: 469.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c3d23d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>widow</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>owner</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>freelance</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seniority   home  time  age  marital records        job  expenses  income  \\\n",
       "0          9   rent    60   30  married      no  freelance        73     129   \n",
       "1         17   rent    60   58    widow      no      fixed        48     131   \n",
       "2         10  owner    36   46  married     yes  freelance        90     200   \n",
       "3          0   rent    60   24   single      no      fixed        63     182   \n",
       "4          0   rent    36   26   single      no      fixed        46     107   \n",
       "\n",
       "   assets  debt  amount  price  default  \n",
       "0       0     0     800    846        0  \n",
       "1       0     0    1000   1658        0  \n",
       "2    3000     0    2000   2985        1  \n",
       "3    2500     0     900   1325        0  \n",
       "4       0     0     310    910        0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467e8fa",
   "metadata": {},
   "source": [
    "##### What are the categorical variables? What are the numerical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a1a86f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['home', 'marital', 'records', 'job']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "92e604c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt',\n",
    "       'amount', 'price']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0361615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = (categorical + numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cda7f",
   "metadata": {},
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "39cc7b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2672, 14), (891, 14), (891, 14))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use Scikit-Learn for that (the train_test_split function) and set the seed to 1.\n",
    "# Step 1 - splitting dataset into full train and test sets first:\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.20,random_state=1) \n",
    "\n",
    "# Step 2 - splitting full train set again into training set and validation set:\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,random_state = 1)\n",
    "\n",
    "# getting the size of train, vaidation and test set:\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "472b155c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2672, 13), (891, 13), (891, 13))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting our target variable column (price) subsets as respective Numpy arrays:\n",
    "y_train = df_train.default.values\n",
    "y_val = df_val.default.values\n",
    "y_test = df_test.default.values\n",
    "\n",
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "del df_train['default']\n",
    "del df_val['default']\n",
    "del df_test['default']\n",
    "\n",
    "# getting the size of train, vaidation and test set after deleting price column:\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d58e4",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c106c",
   "metadata": {},
   "source": [
    "For each numerical variable, use it as score and compute AUC with the \"default\" variable\n",
    "\n",
    "Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1152ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           seniority   default\n",
      "seniority   1.000000 -0.260393\n",
      "default    -0.260393  1.000000\n",
      "             time   default\n",
      "time     1.000000  0.100627\n",
      "default  0.100627  1.000000\n",
      "              age   default\n",
      "age      1.000000 -0.095301\n",
      "default -0.095301  1.000000\n",
      "          expenses   default\n",
      "expenses  1.000000  0.028855\n",
      "default   0.028855  1.000000\n",
      "           income   default\n",
      "income   1.000000 -0.214079\n",
      "default -0.214079  1.000000\n",
      "           assets   default\n",
      "assets   1.000000 -0.097857\n",
      "default -0.097857  1.000000\n",
      "             debt   default\n",
      "debt     1.000000  0.010011\n",
      "default  0.010011  1.000000\n",
      "           amount   default\n",
      "amount   1.000000  0.154549\n",
      "default  0.154549  1.000000\n",
      "           price  default\n",
      "price    1.00000  0.01074\n",
      "default  0.01074  1.00000\n"
     ]
    }
   ],
   "source": [
    "numerical_target = ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt',\n",
    "       'amount', 'price']  \n",
    "\n",
    "for i in numerical_target:\n",
    "    a = df[[i, 'default']].corr() \n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cbd51887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "#roc_auc_score(y_true, y_pred)\n",
    "# Feature is predictions, and target is true values.\n",
    "auc_score = round(roc_auc_score(y_train, -df_train['seniority']),3)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "61b89a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.561"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = round(roc_auc_score(y_train, df_train['time']),3)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "97017173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.687"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = round(roc_auc_score(y_train, -df_train['income']),3)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4e6fd82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = round(roc_auc_score(y_train, -df_train['debt']),3)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16743835",
   "metadata": {},
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "Ans. seniority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6b1f6449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seniority 0.298 -0.298\n",
      "time 0.561 0.561\n",
      "age 0.433 -0.433\n",
      "expenses 0.501 0.501\n",
      "income 0.313 -0.313\n",
      "assets 0.365 -0.365\n",
      "debt 0.499 -0.499\n",
      "amount 0.588 0.588\n",
      "price 0.486 -0.486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in df_train[numerical].columns:\n",
    "    # auc scores\n",
    "    auc_score = round(roc_auc_score(y_train, df_train[i]),3)\n",
    "    if auc_score < 0.5:\n",
    "        new_auc = (auc_score * -1)\n",
    "    else:\n",
    "        new_auc = auc_score\n",
    "    print(i, auc_score, new_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b99ebc",
   "metadata": {},
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "Ans. seniority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f52a7",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1169e",
   "metadata": {},
   "source": [
    "From now on, use these columns only:\n",
    "\n",
    "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c422d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Step 1 - Including above feature columns when using one-hot encoding - \n",
    "# creating an instance of the class DictVectorizer()\n",
    "dv = DictVectorizer(sparse=False)   # turns off result as a sparse matrix instead produces a Numpy array\n",
    "\n",
    "train_dicts = df_train[features].to_dict(orient='records')\n",
    "\n",
    "# Combined fit and transform dictionary - for training dataset:\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Step 2 - Fitting the Logistic regresseion model on the training dataset -\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# intitiating Log. regression model and training it on our full train set:\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, random_state=42,max_iter=1000) \n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Step 3 - repeating above process for validation dataset:\n",
    "# Combined fit and transform dictionary - for validation dataset:\n",
    "val_dicts = df_val[features].to_dict(orient='records')\n",
    "\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# predicting on the validation dataset and round it to 3 decimal digits:\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4a65aa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - Calculating the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "# for validation set:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "AUC_score = round(roc_auc_score(y_val, y_pred),3)\n",
    "AUC_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31163d",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "Ans. 0.612"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62660a2f",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "\n",
    "For each threshold, compute precision and recall\n",
    "\n",
    "Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "62fa8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing TPR and FPR for any model as a Function:\n",
    "scores = []\n",
    "\n",
    "# Step 1 - get all the possible threshold values - using arange() function:\n",
    "thresholds = np.arange(0.0, 1.0, 0.1)\n",
    "\n",
    "    # Step 2 - for all threshold levels getting the confusion tables as list of tuples, scores:\n",
    "for t in thresholds:\n",
    "    # Actual default and not default - as binary arrays::\n",
    "    actual_positive = (y_val == 1)  # customers actually going to default \n",
    "    actual_negative = (y_val == 0)  # customers actually not going to default\n",
    "\n",
    "    # Predicting default and not default - as binary arrays:\n",
    "    predict_positive = (y_pred >= t)  # predict that customers are going to default\n",
    "    predict_negative = (y_pred < t)   # predict that customers are not going to default\n",
    "\n",
    "    # Combining predictions and actuals - using logical operators in Numpy:\n",
    "    # computing True Positives - \n",
    "    tp = (predict_positive & actual_positive).sum()  # returns true only if both are True\n",
    "\n",
    "    # computing True Negatives -\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    # computing False Positives -\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "\n",
    "    # computing False Negatives -\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    # computing precision and recall - \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    scores.append((t, tp, fp, fn, tn, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d0e5fd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>246</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276094</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>114</td>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>581</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp   fp   fn   tn  precision    recall\n",
       "0        0.0  246  645    0    0   0.276094  1.000000\n",
       "1        0.1  114   64  132  581   0.640449  0.463415\n",
       "2        0.2  114   64  132  581   0.640449  0.463415\n",
       "3        0.3  114   64  132  581   0.640449  0.463415\n",
       "4        0.4  114   64  132  581   0.640449  0.463415\n",
       "5        0.5  114   64  132  581   0.640449  0.463415\n",
       "6        0.6  114   64  132  581   0.640449  0.463415\n",
       "7        0.7  114   64  132  581   0.640449  0.463415\n",
       "8        0.8  114   64  132  581   0.640449  0.463415\n",
       "9        0.9  114   64  132  581   0.640449  0.463415"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Step 3 - putting all the confusion matrices created for each threshold into a DataFrame:\n",
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'precision', 'recall']  # specifying column names for df\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4f1a283e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5 - plotting the Precision and Recall using different thresholds:\n",
    "plt.plot(df_scores.threshold, df_scores['precision'],label='Precision')\n",
    "plt.plot(df_scores.threshold, df_scores['recall'],label='Recall')\n",
    "plt.xlabel('thresholds')\n",
    "plt.ylabel('precision and recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d7ec9",
   "metadata": {},
   "source": [
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "Ans. 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c45e91",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d245e4",
   "metadata": {},
   "source": [
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "071c7d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  F1_score\n",
       "0        0.0  0.432718\n",
       "1        0.1  0.537736\n",
       "2        0.2  0.537736\n",
       "3        0.3  0.537736\n",
       "4        0.4  0.537736\n",
       "5        0.5  0.537736\n",
       "6        0.6  0.537736\n",
       "7        0.7  0.537736\n",
       "8        0.8  0.537736\n",
       "9        0.9  0.537736"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing TPR and FPR for any model as a Function:\n",
    "scores = []\n",
    "\n",
    "# Step 1 - get all the possible threshold values - using arange() function:\n",
    "thresholds = np.arange(0.0, 1.0, 0.1)\n",
    "\n",
    "    # Step 2 - for all threshold levels getting the confusion tables as list of tuples, scores:\n",
    "for t in thresholds:\n",
    "    # Actual default and not default - as binary arrays::\n",
    "    actual_positive = (y_val == 1)  # customers actually going to default \n",
    "    actual_negative = (y_val == 0)  # customers actually not going to default\n",
    "\n",
    "    # Predicting default and not default - as binary arrays:\n",
    "    predict_positive = (y_pred >= t)  # predict that customers are going to default\n",
    "    predict_negative = (y_pred < t)   # predict that customers are not going to default\n",
    "\n",
    "    # Combining predictions and actuals - using logical operators in Numpy:\n",
    "    # computing True Positives - \n",
    "    tp = (predict_positive & actual_positive).sum()  # returns true only if both are True\n",
    "\n",
    "    # computing True Negatives -\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    # computing False Positives -\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "\n",
    "    # computing False Negatives -\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    # computing precision and recall - \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # computing F1 score - F1 = 2 * P * R / (P + R)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    scores.append((t, F1))\n",
    "\n",
    "    # Step 3 - putting all the confusion matrices created for each threshold into a DataFrame:\n",
    "    columns = ['threshold', 'F1_score']  # specifying column names for df\n",
    "    df_scores = pd.DataFrame(scores, columns=columns)\n",
    "    \n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca42ee",
   "metadata": {},
   "source": [
    "At which threshold F1 is maximal?\n",
    "\n",
    "Ans. 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dca79d",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c788370",
   "metadata": {},
   "source": [
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "Iterate over different folds of df_full_train\n",
    "\n",
    "Split the data into train and validation\n",
    "\n",
    "Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "Use AUC to evaluate the model on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "86da3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 -\n",
    "# Function 1 - Creating a function to train our DataFrame:\n",
    "def train(df_train, y_train):\n",
    "    dicts = df_train[features].to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)     # C parameter is equivalent to regularization parameter\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7604f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, model = train(df_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d1062c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - \n",
    "# Function 2 - Creating another function to predict:\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[features].to_dict(orient='records')  # converts df to list of dictionaries\n",
    "    \n",
    "    X = dv.transform(dicts)  # creates a feature matrix using the vectorizer\n",
    "    \n",
    "    y_pred = model.predict_proba(X)[:, 1]  # uses the model\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "97e07e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(df_val, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6299baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library to track each iteration in a Cross Validation run\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Step 3 - Using the K-fold Cross Validation and above 2 created functions - \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d1647b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0ed41e45354ddc8eb6f19f5754bcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.814 +- 0.015\n",
      "0.001 0.814 +- 0.015\n",
      "0.01 0.814 +- 0.015\n",
      "0.1 0.814 +- 0.015\n",
      "0.5 0.814 +- 0.015\n",
      "1 0.814 +- 0.015\n",
      "5 0.814 +- 0.015\n",
      "10 0.814 +- 0.015\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0, 0.001, 0.01, 0.1, 0.5, 1, 5, 10]):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "   \n",
    "    scores = []\n",
    "    \n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        \n",
    "        # Selecting part of dataset as 3 subsets for model:\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.default.values   # our target variable values as Numpy array for train and validation sets\n",
    "        y_val = df_val.default.values\n",
    "\n",
    "        dv, model = train(df_train, y_train)   # using train function created\n",
    "        y_pred = predict(df_val, dv, model)   # using predict function created\n",
    "\n",
    "        # compute auc for ROC Curve:\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "        \n",
    "        # Computing mean of scores and std deviation of score:\n",
    "    print('%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f4878",
   "metadata": {},
   "source": [
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "Ans. 0.014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44ddfe",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1e546",
   "metadata": {},
   "source": [
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "\n",
    "Initialize KFold with the same parameters as previously\n",
    "\n",
    "Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "\n",
    "Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f86fc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 -\n",
    "# Function 1 - Creating a function to train our DataFrame:\n",
    "def train(df_train, y_train,C):\n",
    "    dicts = df_train[features].to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)     # C parameter is equivalent to regularization parameter\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "41fef515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - \n",
    "# Function 2 - Creating another function to predict:\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[features].to_dict(orient='records')  # converts df to list of dictionaries\n",
    "    \n",
    "    X = dv.transform(dicts)  # creates a feature matrix using the vectorizer\n",
    "    \n",
    "    y_pred = model.predict_proba(X)[:, 1]  # uses the model\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0c9cac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.808 +- 0.012\n",
      "0.1 0.813 +- 0.014\n",
      "1 0.814 +- 0.015\n",
      "10 0.814 +- 0.015\n"
     ]
    }
   ],
   "source": [
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "   \n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        \n",
    "        # Selecting part of dataset as 3 subsets for model:\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.default.values   # our target variable values as Numpy array for train and validation sets\n",
    "        y_val = df_val.default.values\n",
    "\n",
    "        dv, model = train(df_train, y_train,C)   # using train function created\n",
    "        y_pred = predict(df_val, dv, model)   # using predict function created\n",
    "\n",
    "        # compute auc for ROC Curve:\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "        \n",
    "        # Computing mean of scores and std deviation of score:\n",
    "    print('%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca34bf3",
   "metadata": {},
   "source": [
    "Which C leads to the best mean score?\n",
    "\n",
    "Ans. 1 (smallest C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
