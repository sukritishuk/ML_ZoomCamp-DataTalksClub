{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810ac2da",
   "metadata": {},
   "source": [
    "## Session #1 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b63df",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fba932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the version of NumPy that you installed?\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8334e13",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e896e3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the version of Pandas?\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f473707",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40be72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine Fuel Type</th>\n",
       "      <th>Engine HP</th>\n",
       "      <th>Engine Cylinders</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Driven_Wheels</th>\n",
       "      <th>Number of Doors</th>\n",
       "      <th>Market Category</th>\n",
       "      <th>Vehicle Size</th>\n",
       "      <th>Vehicle Style</th>\n",
       "      <th>highway MPG</th>\n",
       "      <th>city mpg</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Factory Tuner,Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>3916</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Make       Model  Year             Engine Fuel Type  Engine HP  \\\n",
       "0  BMW  1 Series M  2011  premium unleaded (required)      335.0   \n",
       "1  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "2  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "3  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "4  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "\n",
       "   Engine Cylinders Transmission Type     Driven_Wheels  Number of Doors  \\\n",
       "0               6.0            MANUAL  rear wheel drive              2.0   \n",
       "1               6.0            MANUAL  rear wheel drive              2.0   \n",
       "2               6.0            MANUAL  rear wheel drive              2.0   \n",
       "3               6.0            MANUAL  rear wheel drive              2.0   \n",
       "4               6.0            MANUAL  rear wheel drive              2.0   \n",
       "\n",
       "                         Market Category Vehicle Size Vehicle Style  \\\n",
       "0  Factory Tuner,Luxury,High-Performance      Compact         Coupe   \n",
       "1                     Luxury,Performance      Compact   Convertible   \n",
       "2                Luxury,High-Performance      Compact         Coupe   \n",
       "3                     Luxury,Performance      Compact         Coupe   \n",
       "4                                 Luxury      Compact   Convertible   \n",
       "\n",
       "   highway MPG  city mpg  Popularity   MSRP  \n",
       "0           26        19        3916  46135  \n",
       "1           28        19        3916  40650  \n",
       "2           28        20        3916  36350  \n",
       "3           28        18        3916  29450  \n",
       "4           28        18        3916  34500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('car-price-data-ML ZoomCamp - Session 1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc1be3",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbaf4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean    61546.763473\n",
       "Name: BMW, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the average price of BMW cars in the dataset?\n",
    "grouped_data = data.groupby('Make')['MSRP'].agg(['mean'])\n",
    "grouped_data.loc['BMW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f31aa1",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586f236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a subset of cars after year 2015 (inclusive, i.e. 2015 and after). How many of them have missing values for Engine HP?\n",
    "Year_after_2015 = (data[data.Year >= 2015]) \n",
    "missing_HP_after_2015 = Year_after_2015['Engine HP'].isnull().sum()\n",
    "missing_HP_after_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e7e4b",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a30a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average \"Engine HP\" in the dataset.\n",
    "mean_hp_before = data['Engine HP'].mean()\n",
    "print(round(mean_hp_before))\n",
    "\n",
    "# Use the fillna method and to fill the missing values in \"Engine HP\" with the mean value from the previous step.\n",
    "data['Engine HP'].fillna(mean_hp_before, inplace=True)\n",
    "\n",
    "# Now, calcualte the average of \"Engine HP\" again.\n",
    "mean_hp_after = data['Engine HP'].mean()\n",
    "print(round(mean_hp_after))\n",
    "\n",
    "# Has it changed?\n",
    "# No Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039c1e5",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedaf026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.,   8.,  15.],\n",
       "       [563.,  12.,  19.],\n",
       "       [563.,  12.,  21.],\n",
       "       [563.,  12.,  20.],\n",
       "       [322.,  12.,  15.],\n",
       "       [453.,  12.,  19.],\n",
       "       [624.,  12.,  21.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the \"Rolls-Royce\" cars from the dataset.\n",
    "rolls_royce_data = data[data['Make'] == 'Rolls-Royce']\n",
    "\n",
    "# Select only columns \"Engine HP\", \"Engine Cylinders\", \"highway MPG\".\n",
    "select_rr = rolls_royce_data[['Engine HP','Engine Cylinders','highway MPG']]\n",
    "\n",
    "# Now drop all duplicated rows using drop_duplicates method (you should get a dataframe with 7 rows).\n",
    "unduplicated_rr = select_rr.drop_duplicates()\n",
    "\n",
    "# Get the underlying NumPy array. Let's call it X.\n",
    "X = unduplicated_rr.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64208964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.754801e+06, 3.965600e+04, 6.519600e+04],\n",
       "       [3.965600e+04, 9.280000e+02, 1.500000e+03],\n",
       "       [6.519600e+04, 1.500000e+03, 2.454000e+03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute matrix-matrix multiplication between the transpose of X and X. To get the transpose, use X.T. Let's call the result XTX.\n",
    "XTX = (X.T).dot(X)\n",
    "XTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6105dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.17815728e-05,  9.06587044e-04, -1.92984188e-03],\n",
       "       [ 9.06587044e-04,  1.05723058e-01, -8.87084092e-02],\n",
       "       [-1.92984188e-03, -8.87084092e-02,  1.05900809e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invert XTX.\n",
    "inverse_XTX = np.linalg.inv(XTX)\n",
    "inverse_XTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780b246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all the elements is 0.032212320677486195\n"
     ]
    }
   ],
   "source": [
    "# What's the sum of all the elements of the result?\n",
    "total = np.sum(inverse_XTX)\n",
    "print(f'Sum of all the elements is {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14063a",
   "metadata": {},
   "source": [
    "### Questions 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50efcba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19989598183186175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array y with values [1000, 1100, 900, 1200, 1000, 850, 1300].\n",
    "y = np.array([1000, 1100, 900, 1200, 1000, 850, 1300])\n",
    "y\n",
    "\n",
    "# Multiply the inverse of XTX with the transpose of X, and then multiply the result by y. Call the result w.\n",
    "#print(inverse_XTX * (X.T))\n",
    "m = inverse_XTX.dot(X.T)\n",
    "w = m.dot(y)\n",
    "\n",
    "# What's the value of the first element of w?.\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98df45e",
   "metadata": {},
   "source": [
    "## Session #2 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d429590",
   "metadata": {},
   "source": [
    "###  Create a regression model for prediction apartment prices - \n",
    "\n",
    "#### (using New York City Airbnb Open Data)\n",
    "\n",
    "Datset - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b211b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.2'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad48a38",
   "metadata": {},
   "source": [
    "#### EDA\n",
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34e158ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5edae",
   "metadata": {},
   "source": [
    "Look at the price variable. Does it have a long tail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7377169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.price.describe()\n",
    "\n",
    "# Computing the log of price column values:\n",
    "price_logs = np.log1p(data.price)\n",
    "\n",
    "# plotting the logarithmic price column values:\n",
    "sns.histplot(price_logs,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240bad1",
   "metadata": {},
   "source": [
    "Plotting the logarithmic values of price column shows that price variable has a long tail towards the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ecdca",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d8c8386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  price  minimum_nights  number_of_reviews  \\\n",
       "0  40.64749  -73.97237    149               1                  9   \n",
       "1  40.75362  -73.98377    225               1                 45   \n",
       "2  40.80902  -73.94190    150               3                  0   \n",
       "3  40.68514  -73.95976     89               1                270   \n",
       "4  40.79851  -73.94399     80              10                  9   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only specific columns from dataset for future use.\n",
    "features = data[['latitude','longitude','price','minimum_nights','number_of_reviews','reviews_per_month',\n",
    "'calculated_host_listings_count','availability_365']]\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905589b5",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Find a feature with missing values. How many missing values does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "038d5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                              0\n",
       "longitude                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01e7fb",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the median (50% percentile) for variable 'minimum_nights'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a179d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48895.000000\n",
       "mean         7.029962\n",
       "std         20.510550\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          3.000000\n",
       "75%          5.000000\n",
       "max       1250.000000\n",
       "Name: minimum_nights, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['minimum_nights'].describe()   # 50th percentile is the same as the median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f66d3",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b3e8810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 48895)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "n = len(data)\n",
    "\n",
    "n_val = int(n * 0.2)   # split 20% into validation set\n",
    "n_test = int(n * 0.2)  # split 20% into testing set\n",
    "n_train = n - n_val - n_test  # remaining training set\n",
    "n, n_val + n_test + n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "689794de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9779, 9779, 29337)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the size of the splitted datasets:\n",
    "n_val, n_test, n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd7cb8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  879, 44383, 15394, ..., 38158,   860, 15795])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the initial dataset, use seed 42.\n",
    "idx = np.arange(n)\n",
    "np.random.seed(42)\n",
    "\n",
    "np.random.shuffle(idx)  # shuffle the data from index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f58cb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9779, 16) (9779, 16) (29337, 16)\n"
     ]
    }
   ],
   "source": [
    "# getting the rows for each set from the shuffled indices:\n",
    "df_val = data.iloc[idx[:n_val]]\n",
    "df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "df_train = data.iloc[idx[n_val + n_test:]]\n",
    "\n",
    "print(df_val.shape, df_test.shape,df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7267a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "# # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "y_val = np.log1p(df_val.price.values)\n",
    "y_test = np.log1p(df_test.price.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d6b9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9779, 15) (9779, 15) (29337, 15)\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "# deleting the price column from Feature matrices of train, validation and test set:\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']\n",
    "\n",
    "print(df_val.shape, df_test.shape,df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b83884",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "#### Option 1 - Filling NaN with 0 - Training  a linear regression model without regularization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a8a9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_features = ['latitude','longitude','minimum_nights','number_of_reviews','reviews_per_month',\n",
    "'calculated_host_listings_count','availability_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "696ac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to extract a subset of a df as an array - \n",
    "def prepare_X(df):\n",
    "    \n",
    "    df_num = df[subset_features]  # feature columns we want in our feature matrix subset\n",
    "    df_num = df_num.fillna(0)  # fill missing values with zeros\n",
    "    X = df_num.values   # extracting only values of subset as a Numpy array\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d0cc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing only above feature columns to create a subset of training dataset:\n",
    "X_train = prepare_X(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "740d038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to predict car price's using 3 features - \n",
    "def train_linear_regression(X,y):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 5 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 6 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15f68dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.87791291, 4.81288069, 5.55153718, ..., 5.02356152, 4.88478955,\n",
       "       4.66641733])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Linear regression model (function) for the training sets to get weights w0 and w:\n",
    "w0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "# computing target variable y_pred -\n",
    "# using weights w0 and w to compute the target variable y_pred:\n",
    "y_pred = w0 + X_train.dot(w)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6146398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the RMSE of actual target variable vs. predicted target variables:\n",
    "def rmse(y,y_pred):\n",
    "    # computing the squared error first:\n",
    "    se = (y - y_pred) ** 2  \n",
    "    # computing the mean of squared errors computed:\n",
    "    mse = se.mean()\n",
    "    # returning the square root of squared error:\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947381a6",
   "metadata": {},
   "source": [
    "#### Option 2 - Filling NaN with Mean value - Training a linear regression model without regularization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5decfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to extract a subset of a df as an array - \n",
    "def prepare_X2(df):\n",
    "    df_num = df[subset_features]  # feature columns we want in our feature matrix subset\n",
    "    df_num = df_num.fillna(df_train['reviews_per_month'].mean())  # fill missing values with mean of column\n",
    "    X2 = df_num.values   # extracting only values of subset as a Numpy array\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5969f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing only above feature columns to create a subset of training dataset:\n",
    "X_train_2 = prepare_X2(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d88377ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to predict car price's using 3 features - \n",
    "def train_linear_regression2(X,y):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 5 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 6 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c57d1b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.86744762, 4.80488808, 5.54883838, ..., 5.01686784, 4.87418674,\n",
       "       4.65564306])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Linear regression model (function) for the training sets to get weights w0 and w:\n",
    "w0, w = train_linear_regression2(X_train_2, y_train)\n",
    "\n",
    "# computing target variable y_pred -\n",
    "# using weights w0 and w to compute the target variable y_pred:\n",
    "y_pred = w0 + X_train_2.dot(w)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5cb6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to calculate the RMSE of actual target variable vs. predicted target variables:\n",
    "def rmse2(y,y_pred):\n",
    "    # computing the squared error first:\n",
    "    se = (y - y_pred) ** 2  \n",
    "    # computing the mean of squared errors computed:\n",
    "    mse = se.mean()\n",
    "    # returning the square root of squared error:\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919619a",
   "metadata": {},
   "source": [
    "#### Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "\n",
    "Option 1 - Filling NaN with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5456bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing subset feature array on to create a validation set:\n",
    "X_val = prepare_X(df_val)\n",
    "\n",
    "y_pred = w0 + X_val.dot(w)   # computing the predicted target variable y for validation set\n",
    "val_score = rmse(y_val, y_pred)   # computing the rmse for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a7ad4",
   "metadata": {},
   "source": [
    "Option 2 - Filling NaN with Mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7266b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing subset feature array on to create a validation set:\n",
    "X_val = prepare_X2(df_val)\n",
    "\n",
    "y_pred = w0 + X_val.dot(w)   # computing the predicted target variable y for validation set\n",
    "val_score2 = rmse2(y_val, y_pred)   # computing the rmse for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ff44a",
   "metadata": {},
   "source": [
    "Which option gives better RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1262ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 RMSE: 0.64\n",
      "Option 2 RMSE: 0.64\n"
     ]
    }
   ],
   "source": [
    "# ound the RMSE scores to 2 decimal digits using round(score, 2)\n",
    "print('Option 1 RMSE:',round(val_score,2))\n",
    "print('Option 2 RMSE:',round(val_score2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416172b",
   "metadata": {},
   "source": [
    "Both Options give almost same RMSE value on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c025c",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Now let's train a regularized linear regression. \n",
    "\n",
    "For this question, fill the NAs with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faef5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Regularized function to predict price using features - \n",
    "def train_linear_regression_reg(X,y,r):\n",
    "    # Step 1 - adding ones for bias term in features matrix - using np.ones() function:\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Step 2 - stacking the array for ones generated in Step 1 to the features' matrix:\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    # Step 3 - compute the gram matrix by dot product of X matrix with X transpose:\n",
    "    XTX = X.T.dot(X)\n",
    "    # Step 4 - # add the alpha term r to diagonals of matrix use np.eye() function:\n",
    "    XTX = XTX + r * np.eye(XTX.shape[0])   \n",
    "    \n",
    "    # Step 5 - compute the inverse of XTX computes in Step 3 - using np.linalginv() function:\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    \n",
    "    # Step 6 - compute the weights of the entire car data using dot product multiplication with target variable y:\n",
    "    w_full = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Step 7 - return the computed intercept or bias term and rest of factors of linear regression equation:\n",
    "    return w_full[0], w_full[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666c2c9",
   "metadata": {},
   "source": [
    "Try different values of r from this list: [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10].\n",
    "    \n",
    "Use RMSE to evaluate the model on the validation dataset.\n",
    "\n",
    "Round the RMSE scores to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "069e4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -443.49 RMSE : 3.17\n",
      "1e-06 -443.49 RMSE : 3.22\n",
      "0.0001 -443.49 RMSE : 8.42\n",
      "0.001 -443.49 RMSE : 50.86\n",
      "0.01 -443.49 RMSE : 244.77\n",
      "0.1 -443.49 RMSE : 410.02\n",
      "1 -443.49 RMSE : 439.89\n",
      "5 -443.49 RMSE : 442.76\n",
      "10 -443.49 RMSE : 443.12\n"
     ]
    }
   ],
   "source": [
    "# Using the newly created Regularized function:\n",
    "# Finding the best regularization parameter, r for our Linear Regression model - \n",
    "# taking a series of r values to test our model and find the RMSE score for each:\n",
    "for m in [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n",
    "    \n",
    "    X_train = prepare_X(df_train)   # function replaces NaN with zeros\n",
    "    wo, w = train_linear_regression_reg(X_train, y_train,r=m)   # training set\n",
    "    \n",
    "    X_val = prepare_X(df_val)    # validation set\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "\n",
    "    score = rmse(y_val,y_pred)   # comparing actual vs prediction target variable in validation set\n",
    "    print(m, round(w0,2), 'RMSE :',round(score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bfc15",
   "metadata": {},
   "source": [
    "#### Which r gives the best RMSE?\n",
    "r = 0.0001 gives a RMSE of 8.42 which is low but not extremely low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f6c1f",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28648e14",
   "metadata": {},
   "source": [
    "We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "\n",
    "Try different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].\n",
    "\n",
    "Fill the missing values with 0 and train a model without regularization.\n",
    "\n",
    "For each seed, evaluate the model on the validation dataset and collect the RMSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6306547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [43813 32734 25276 ... 42613 43567  2732] -443.49 RMSE: 23.14\n",
      "1 [18907 46663 19757 ...  5192 12172 33003] -443.49 RMSE: 7.64\n",
      "2 [22043 39679 45220 ...  6637 35343 23720] -443.49 RMSE: 19.56\n",
      "3 [ 6920 38903 30764 ... 11513  1688  5994] -443.49 RMSE: 17.6\n",
      "4 [25022 38145  2095 ... 27063  8366 17530] -443.49 RMSE: 19.35\n",
      "5 [20531 20353 26436 ... 20463 18638 35683] -443.49 RMSE: 26.13\n",
      "6 [27383  7800 18787 ... 42964 41187 31626] -443.49 RMSE: 22.89\n",
      "7 [13636 25054 15227 ...   919 38467 10742] -443.49 RMSE: 20.78\n",
      "8 [42099 22672  8754 ... 18417 25940  4547] -443.49 RMSE: 21.53\n",
      "9 [25415  1329 31738 ... 22584   501 20828] -443.49 RMSE: 28.24\n"
     ]
    }
   ],
   "source": [
    "RMSE_scores = []\n",
    "\n",
    "for a in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    # For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n",
    "    n = len(data)\n",
    "\n",
    "    # Shuffle the initial dataset, use different seed values from list:\n",
    "    np.random.seed(a)\n",
    "    \n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)# shuffle the data from index\n",
    "    \n",
    "    n_val = int(n * 0.2)   # split 20% into validation set\n",
    "    n_test = int(n * 0.2)  # split 20% into testing set\n",
    "    n_train = n - n_val - n_test  # remaining training set\n",
    "\n",
    "\n",
    "    # getting the rows for each set from the shuffled indices:\n",
    "    df_val = data.iloc[idx[:n_val]]\n",
    "    df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "    df_train = data.iloc[idx[n_val + n_test:]]\n",
    "   \n",
    "    # Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "    # # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "    y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "    y_val = np.log1p(df_val.price.values)\n",
    "    y_test = np.log1p(df_test.price.values)\n",
    "    \n",
    "\n",
    "    # Make sure that the target value ('price') is not in your dataframe.\n",
    "    # deleting the price column from Feature matrices of train, validation and test set:\n",
    "    del df_train['price']\n",
    "    del df_val['price']\n",
    "    del df_test['price']\n",
    "\n",
    "    X_train = prepare_X(df_train)   # function replaces NaN with zeros\n",
    "       \n",
    "    # Training a model without regularization:\n",
    "    wo, w = train_linear_regression(X_train, y_train)   # training set\n",
    "\n",
    "    X_val = prepare_X(df_val) # validation set\n",
    "    \n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "\n",
    "    score = rmse(y_val,y_pred)   # comparing actual vs prediction target variable in validation set\n",
    "    \n",
    "    print(a, idx, round(w0,2),'RMSE:',round(score,2))   \n",
    "    RMSE_scores.append(score)\n",
    "\n",
    "RMSE_std = np.std(RMSE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "baee8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302255023811292"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(RMSE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18ed8551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the standard deviation of all the scores? To compute the standard deviation, use np.std:\n",
    "RMSE_std\n",
    "\n",
    "# Round the result to 3 decimal digits:\n",
    "(round(RMSE_std, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c1ef0",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "483844b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset like previously, use seed 9.\n",
    "n = len(data)\n",
    "\n",
    "# Shuffle the initial dataset, use different seed values from list:\n",
    "np.random.seed(9)\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)# shuffle the data from index\n",
    "    \n",
    "n_val = int(n * 0.2)   # split 20% into validation set\n",
    "n_test = int(n * 0.2)  # split 20% into testing set\n",
    "n_train = n - n_val - n_test  # remaining training set\n",
    "\n",
    "# getting the rows for each set from the shuffled indices:\n",
    "df_val = data.iloc[idx[:n_val]]\n",
    "df_test = data.iloc[idx[n_val:n_val+n_test]]\n",
    "df_train = data.iloc[idx[n_val + n_test:]]\n",
    "   \n",
    "# Slicing out price column from the 3 split sets and assign to y variables for each:\n",
    "# # Apply the log transformation to the price variable using the np.log1p() function.\n",
    "y_train = np.log1p(df_train.price.values)   # getting numpy arrays instead of Pandas series for target variable\n",
    "y_val = np.log1p(df_val.price.values)\n",
    "y_test = np.log1p(df_test.price.values)\n",
    "    \n",
    "\n",
    "# Make sure that the target value ('price') is not in your dataframe.\n",
    "# deleting the price column from Feature matrices of train, validation and test set:\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e19624",
   "metadata": {},
   "source": [
    "Combine train and validation datasets.\n",
    "\n",
    "Fill the missing values with 0 and train a model with r=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "181d8493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6404588269895755"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train = pd.concat([df_train,df_val])\n",
    "# resetting index of combined training set:\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "# Combining features matrix for training and validation set using full training set as input to the prepare_X  function:\n",
    "X_full_train = prepare_X(df_full_train)\n",
    "X_full_train \n",
    "\n",
    "# Combining y target variable array of training and validation set:\n",
    "y_full_train = np.concatenate([y_train, y_val])\n",
    "y_full_train\n",
    "\n",
    "\n",
    "# Running the Regularized linear regression model and calculating the RMSE score on testing dataset:\n",
    "w0, w = train_linear_regression_reg(X_full_train,y_full_train, r=0.001)\n",
    "\n",
    "X_test = prepare_X(df_test)\n",
    "y_pred = w0 + X_test.dot(w)\n",
    "score = rmse(y_test, y_pred)\n",
    "\n",
    "# What's the RMSE on the test dataset?\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
